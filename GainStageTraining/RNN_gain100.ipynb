{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat, wavfile\n",
    "import random\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = []\n",
    "pathlist = Path('DataIn').glob('*.wav')\n",
    "for p in pathlist:\n",
    "  fs, x = wavfile.read(str(p))\n",
    "  fs, y = wavfile.read('Data100/'+p.name)\n",
    "  data.append([x, y])\n",
    "\n",
    "# shuffle data\n",
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate x and y data\n",
    "x_values = []\n",
    "y_values = []\n",
    "\n",
    "for d in data:\n",
    "    x_values.append(d[0][14000:])\n",
    "    y_values.append(d[1][14000:])\n",
    "\n",
    "x_values = np.asarray(x_values) / 2**15\n",
    "y_values = (np.asarray(y_values) / 2**15) * 2\n",
    "print(np.shape(x_values))\n",
    "print(np.shape(y_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot sample data point\n",
    "idx = 10\n",
    "plt.plot(x_values[idx])\n",
    "plt.plot(y_values[idx])\n",
    "# plt.xlim(2000, 3000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use float32 data type...\n",
    "x_values = x_values.astype(np.float32)\n",
    "y_values = y_values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and validation data\n",
    "NUM_TRAIN = 400\n",
    "NUM_VAL = 25\n",
    "x_train, x_val = np.split(x_values, [NUM_TRAIN])\n",
    "y_train, y_val = np.split(y_values, [NUM_TRAIN])\n",
    "\n",
    "print(np.shape(x_train))\n",
    "print(np.shape(x_val))\n",
    "print(np.shape(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape data\n",
    "NUM_SAMPLES=8050\n",
    "IN_train    = np.reshape(x_train, (NUM_TRAIN, NUM_SAMPLES, 1))\n",
    "IN_validate = np.reshape(x_val,   (NUM_VAL,   NUM_SAMPLES, 1))\n",
    "\n",
    "OUT_train    = np.reshape(y_train, (NUM_TRAIN, NUM_SAMPLES, 1))\n",
    "OUT_validate = np.reshape(y_val,   (NUM_VAL,   NUM_SAMPLES, 1))\n",
    "\n",
    "print(np.shape(IN_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "# GRU Layer\n",
    "model.add(keras.layers.GRU(units=8, input_shape=(NUM_SAMPLES,1), return_sequences=True, bias_initializer='random_uniform'))\n",
    "\n",
    "# Final layer is 1 neuron -> single value output\n",
    "model.add(keras.layers.Dense(1))\n",
    "\n",
    "# Adam optimizer\n",
    "opt = keras.optimizers.Adam(learning_rate=2.0e-3)\n",
    "\n",
    "# Error-to-Signal ratio loss function\n",
    "def esr_loss(target_y, predicted_y):\n",
    "  return tf.reduce_sum(tf.square(target_y - predicted_y)) / tf.reduce_sum(tf.square(target_y))\n",
    "\n",
    "model.compile(optimizer=opt, loss=esr_loss, metrics=['mse'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(IN_train, OUT_train, epochs=1000, validation_data=(IN_validate, OUT_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'g.', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot error\n",
    "plt.clf()\n",
    "mse = history.history['mse']\n",
    "val_mse = history.history['val_mse']\n",
    "\n",
    "plt.plot(epochs, mse, 'g.', label='Training MSE')\n",
    "plt.plot(epochs, val_mse, 'b.', label='Validation MSE')\n",
    "plt.title('Training and validation mean square error')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test prediction\n",
    "idx = 3\n",
    "predictions = model.predict(x_train[idx].reshape(1, NUM_SAMPLES, 1))\n",
    "print(np.shape(predictions))\n",
    "\n",
    "# Plot the predictions along with to the test data\n",
    "plt.clf()\n",
    "plt.title('Training data predicted vs actual values')\n",
    "plt.plot(y_train[idx], 'b', label='Actual')\n",
    "plt.plot(predictions.flatten(), 'r--', label='Predicted')\n",
    "plt.legend()\n",
    "plt.xlim(2000, 3000)\n",
    "plt.xlabel('Time [samples]')\n",
    "plt.ylabel('Voltage [V]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test prediction\n",
    "def freqSmooth(x, sm=1.0/24.0):\n",
    "    s = sm if sm > 1.0 else np.sqrt(2.0**sm)\n",
    "    N = len(x)\n",
    "    y = np.zeros_like(x)\n",
    "    for i in range(N):\n",
    "        i1 = max(int(np.floor(i/s)), 0)\n",
    "        i2 = min(int(np.floor(i*s)+1), N-1)\n",
    "        if i2 > i1:\n",
    "            y[i] = np.mean(x[i1:i2])\n",
    "    return y\n",
    "\n",
    "idx = 3\n",
    "predictions = model.predict(x_train[idx].reshape(1, NUM_SAMPLES, 1))\n",
    "print(np.shape(predictions))\n",
    "\n",
    "pred_fft = freqSmooth(20 * np.log10(np.abs(np.fft.rfft(predictions.flatten()))))\n",
    "target_fft = freqSmooth(20 * np.log10(np.abs(np.fft.rfft(y_train[idx]))))\n",
    "freqs = np.fft.rfftfreq(NUM_SAMPLES, 1.0 / 44100.0)\n",
    "\n",
    "# Plot the predictions along with to the test data\n",
    "plt.clf()\n",
    "plt.title('Training data predicted vs actual values')\n",
    "plt.semilogx(freqs, target_fft, 'b', label='Actual')\n",
    "plt.semilogx(freqs, pred_fft, 'r--', label='Predicted')\n",
    "plt.legend()\n",
    "plt.xlim(50, 20000)\n",
    "plt.ylim(-5)\n",
    "plt.xlabel('Frequency [Hz]')\n",
    "plt.ylabel('Magnitude [dB]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export weights....\n",
    "print('GRU Kernel Weights...')\n",
    "print(model.weights[0].numpy())\n",
    "\n",
    "print('GRU Recurrent Weights...')\n",
    "print(model.weights[1].numpy())\n",
    "\n",
    "print('GRU bias...')\n",
    "print(model.weights[2].numpy())\n",
    "\n",
    "print('Dense Kernel Weights...')\n",
    "print(model.weights[3].numpy())\n",
    "\n",
    "print('Dense bias...')\n",
    "print(model.weights[4].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}